{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np            \n",
    "import pandas as pd        \n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras, math\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, GlobalAveragePooling2D, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils import resample\n",
    "from vit_keras import vit\n",
    "\n",
    "#Đường dẫn thư mục train và test\n",
    "train_path = r'.\\train'\n",
    "test_path = r'.\\test'\n",
    "val_path = r'.\\val'\n",
    "\n",
    "batch_size = 32 \n",
    "\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "image_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8,1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data augmentation for testing/validation\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1943 images belonging to 2 classes.\n",
      "Found 611 images belonging to 2 classes.\n",
      "Found 497 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training data generator\n",
    "train_generator = image_gen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "# Testing data generator\n",
    "test = test_data_gen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='rgb', \n",
    "    shuffle=False,\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "validation_generator = image_gen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1_Normal': 0, '2_Disease': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\vit_keras\\utils.py:81: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.763157894736842, 1: 1.763157894736842}\n",
      "Epoch 1/20\n",
      "61/61 [==============================] - 1560s 26s/step - loss: 1.0073 - accuracy: 0.7159 - val_loss: 0.5229 - val_accuracy: 0.7304 - lr: 3.0000e-05\n",
      "Epoch 2/20\n",
      "61/61 [==============================] - 1617s 26s/step - loss: 0.8634 - accuracy: 0.7576 - val_loss: 0.6661 - val_accuracy: 0.6217 - lr: 3.0000e-05\n",
      "Epoch 3/20\n",
      "61/61 [==============================] - 1593s 26s/step - loss: 0.7752 - accuracy: 0.7761 - val_loss: 0.5651 - val_accuracy: 0.7022 - lr: 3.0000e-05\n",
      "Epoch 4/20\n",
      "61/61 [==============================] - 1587s 26s/step - loss: 0.7511 - accuracy: 0.7931 - val_loss: 0.5516 - val_accuracy: 0.7264 - lr: 3.0000e-05\n",
      "Epoch 5/20\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.7266 - accuracy: 0.8034 \n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "61/61 [==============================] - 1586s 26s/step - loss: 0.7266 - accuracy: 0.8034 - val_loss: 0.5275 - val_accuracy: 0.7404 - lr: 9.0000e-06\n",
      "Epoch 6/20\n",
      "61/61 [==============================] - 1585s 26s/step - loss: 0.6717 - accuracy: 0.8199 - val_loss: 0.4763 - val_accuracy: 0.7525 - lr: 9.0000e-06\n",
      "Epoch 7/20\n",
      "61/61 [==============================] - 1584s 26s/step - loss: 0.6523 - accuracy: 0.8204 - val_loss: 0.5387 - val_accuracy: 0.7223 - lr: 9.0000e-06\n",
      "Epoch 8/20\n",
      "61/61 [==============================] - 1585s 26s/step - loss: 0.6500 - accuracy: 0.8224 - val_loss: 0.4403 - val_accuracy: 0.8068 - lr: 9.0000e-06\n",
      "Epoch 9/20\n",
      "61/61 [==============================] - 1602s 26s/step - loss: 0.6173 - accuracy: 0.8338 - val_loss: 0.4766 - val_accuracy: 0.7726 - lr: 9.0000e-06\n",
      "Epoch 10/20\n",
      "61/61 [==============================] - 1586s 26s/step - loss: 0.6329 - accuracy: 0.8410 - val_loss: 0.5417 - val_accuracy: 0.7264 - lr: 9.0000e-06\n",
      "Epoch 11/20\n",
      "61/61 [==============================] - 1590s 26s/step - loss: 0.6155 - accuracy: 0.8369 - val_loss: 0.5420 - val_accuracy: 0.7284 - lr: 8.1435e-06\n",
      "Epoch 12/20\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.8358 \n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 2.210572938565747e-06.\n",
      "61/61 [==============================] - 1593s 26s/step - loss: 0.6013 - accuracy: 0.8358 - val_loss: 0.4994 - val_accuracy: 0.7586 - lr: 2.2106e-06\n",
      "Epoch 13/20\n",
      "61/61 [==============================] - 1589s 26s/step - loss: 0.6005 - accuracy: 0.8343 - val_loss: 0.4475 - val_accuracy: 0.7787 - lr: 2.0002e-06\n",
      "Epoch 14/20\n",
      "61/61 [==============================] - 1588s 26s/step - loss: 0.6060 - accuracy: 0.8384 - val_loss: 0.4168 - val_accuracy: 0.7887 - lr: 1.8099e-06\n",
      "Epoch 15/20\n",
      "61/61 [==============================] - 1589s 26s/step - loss: 0.5986 - accuracy: 0.8466 - val_loss: 0.4813 - val_accuracy: 0.7626 - lr: 1.6376e-06\n",
      "Epoch 16/20\n",
      "61/61 [==============================] - 1589s 26s/step - loss: 0.5772 - accuracy: 0.8471 - val_loss: 0.4696 - val_accuracy: 0.7565 - lr: 1.4818e-06\n",
      "Epoch 17/20\n",
      "61/61 [==============================] - 1594s 26s/step - loss: 0.5858 - accuracy: 0.8451 - val_loss: 0.4133 - val_accuracy: 0.8169 - lr: 1.3408e-06\n",
      "Epoch 18/20\n",
      "61/61 [==============================] - 1586s 26s/step - loss: 0.5725 - accuracy: 0.8502 - val_loss: 0.4658 - val_accuracy: 0.7726 - lr: 1.2132e-06\n",
      "Epoch 19/20\n",
      "61/61 [==============================] - 1581s 26s/step - loss: 0.5711 - accuracy: 0.8456 - val_loss: 0.4852 - val_accuracy: 0.7646 - lr: 1.0977e-06\n",
      "Epoch 20/20\n",
      "61/61 [==============================] - 1302s 21s/step - loss: 0.5850 - accuracy: 0.8502 - val_loss: 0.4949 - val_accuracy: 0.7626 - lr: 9.9327e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2cc81596c40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Vision Transformer model\n",
    "vit_model = vit.vit_b16(\n",
    "    image_size=img_height,\n",
    "    activation='sigmoid',\n",
    "    pretrained=True,\n",
    "    include_top=True,\n",
    "    pretrained_top=False,\n",
    "    classes=1\n",
    ")\n",
    "\n",
    "# Fine-tune more layers\n",
    "for layer in vit_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with a different optimizer and learning rate\n",
    "vit_model.compile(optimizer=Adam(learning_rate=3e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * math.exp(-0.1)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=8, restore_best_weights=True)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=4, verbose=1, factor=0.3, min_lr=0.000001)\n",
    "callbacks_list = [early, learning_rate_reduction, lr_scheduler]\n",
    "\n",
    "# Compute class weights\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "unique_classes = np.unique(train_generator.classes)\n",
    "weights = compute_sample_weight(class_weight='balanced', y=train_generator.classes)\n",
    "cw = dict(zip(unique_classes, weights))\n",
    "print(cw)\n",
    "\n",
    "# Train the model\n",
    "vit_model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,  # Increase the number of epochs\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=cw,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "vit_model.save('VisionTransformer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 79s 4s/step - loss: 0.3466 - accuracy: 0.8560\n",
      "The testing accuracy is: 85.59738397598267 %\n",
      "20/20 [==============================] - 80s 4s/step\n",
      "Confusion Matrix:\n",
      "[[168  29]\n",
      " [ 59 355]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.74      0.85      0.79       197\n",
      "     Disease       0.92      0.86      0.89       414\n",
      "\n",
      "    accuracy                           0.86       611\n",
      "   macro avg       0.83      0.86      0.84       611\n",
      "weighted avg       0.87      0.86      0.86       611\n",
      "\n",
      "Sensitivity: 85.75%\n",
      "Specificity: 85.28%\n",
      "F1-Score: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_accu = vit_model.evaluate(test)\n",
    "print('The testing accuracy is:', test_accu[1] * 100, '%')\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = vit_model.predict(test)\n",
    "y_pred = np.round(y_pred).astype(int)  # Chuyển đổi dự đoán thành nhãn nhị phân (0 hoặc 1)\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test.classes\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Compute classification report\n",
    "class_report = classification_report(y_true, y_pred, target_names=['Normal', 'Disease'])\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Extract Sensitivity, Specificity, and F1-Score from confusion matrix\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = sensitivity  # Recall là tên khác của Sensitivity\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f'Sensitivity: {sensitivity * 100:.2f}%')\n",
    "print(f'Specificity: {specificity * 100:.2f}%')\n",
    "print(f'F1-Score: {f1_score:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
