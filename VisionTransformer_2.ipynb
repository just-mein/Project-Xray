{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np            \n",
    "import pandas as pd        \n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras, math\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, GlobalAveragePooling2D, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils import resample\n",
    "from vit_keras import vit\n",
    "\n",
    "#Đường dẫn thư mục train và test\n",
    "train_path = r'.\\train'\n",
    "test_path = r'.\\test'\n",
    "val_path = r'.\\val'\n",
    "\n",
    "batch_size = 32 \n",
    "\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "image_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8,1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data augmentation for testing/validation\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1943 images belonging to 2 classes.\n",
      "Found 611 images belonging to 2 classes.\n",
      "Found 497 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training data generator\n",
    "train_generator = image_gen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "# Testing data generator\n",
    "test = test_data_gen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='rgb', \n",
    "    shuffle=False,\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "validation_generator = image_gen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1_Normal': 0, '2_Disease': 1}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-B_16_imagenet21k+imagenet2012.npz\n",
      "347502902/347502902 [==============================] - 323s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\vit_keras\\utils.py:81: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.763157894736842, 1: 1.763157894736842}\n",
      "Epoch 1/20\n",
      "61/61 [==============================] - 664s 11s/step - loss: 1.0339 - accuracy: 0.7046 - val_loss: 0.6572 - val_accuracy: 0.6338 - lr: 3.0000e-05\n",
      "Epoch 2/20\n",
      "61/61 [==============================] - 649s 11s/step - loss: 0.8501 - accuracy: 0.7663 - val_loss: 0.5183 - val_accuracy: 0.7565 - lr: 3.0000e-05\n",
      "Epoch 3/20\n",
      "61/61 [==============================] - 649s 11s/step - loss: 0.7904 - accuracy: 0.7849 - val_loss: 0.5263 - val_accuracy: 0.7304 - lr: 3.0000e-05\n",
      "Epoch 4/20\n",
      "61/61 [==============================] - 655s 11s/step - loss: 0.7373 - accuracy: 0.7967 - val_loss: 0.5343 - val_accuracy: 0.7485 - lr: 3.0000e-05\n",
      "Epoch 5/20\n",
      "61/61 [==============================] - 656s 11s/step - loss: 0.7283 - accuracy: 0.8034 - val_loss: 0.5394 - val_accuracy: 0.7565 - lr: 3.0000e-05\n",
      "Epoch 6/20\n",
      "61/61 [==============================] - 649s 11s/step - loss: 0.7496 - accuracy: 0.7962 - val_loss: 0.4546 - val_accuracy: 0.7907 - lr: 3.0000e-05\n",
      "Epoch 7/20\n",
      "61/61 [==============================] - 655s 11s/step - loss: 0.6710 - accuracy: 0.8255 - val_loss: 0.5216 - val_accuracy: 0.7505 - lr: 3.0000e-05\n",
      "Epoch 8/20\n",
      "61/61 [==============================] - 643s 11s/step - loss: 0.6686 - accuracy: 0.8230 - val_loss: 0.5213 - val_accuracy: 0.7243 - lr: 3.0000e-05\n",
      "Epoch 9/20\n",
      "61/61 [==============================] - 644s 11s/step - loss: 0.6407 - accuracy: 0.8379 - val_loss: 0.4477 - val_accuracy: 0.7827 - lr: 3.0000e-05\n",
      "Epoch 10/20\n",
      "61/61 [==============================] - 645s 11s/step - loss: 0.6122 - accuracy: 0.8420 - val_loss: 0.4291 - val_accuracy: 0.8109 - lr: 3.0000e-05\n",
      "Epoch 11/20\n",
      "61/61 [==============================] - 648s 11s/step - loss: 0.6148 - accuracy: 0.8441 - val_loss: 0.5146 - val_accuracy: 0.7525 - lr: 2.7145e-05\n",
      "Epoch 12/20\n",
      "61/61 [==============================] - 648s 11s/step - loss: 0.5749 - accuracy: 0.8513 - val_loss: 0.4443 - val_accuracy: 0.7787 - lr: 2.4562e-05\n",
      "Epoch 13/20\n",
      "61/61 [==============================] - 648s 11s/step - loss: 0.5490 - accuracy: 0.8580 - val_loss: 0.4206 - val_accuracy: 0.8229 - lr: 2.2225e-05\n",
      "Epoch 14/20\n",
      "61/61 [==============================] - 643s 11s/step - loss: 0.5582 - accuracy: 0.8590 - val_loss: 0.5048 - val_accuracy: 0.7867 - lr: 2.0110e-05\n",
      "Epoch 15/20\n",
      "61/61 [==============================] - 649s 11s/step - loss: 0.5464 - accuracy: 0.8605 - val_loss: 0.4536 - val_accuracy: 0.8048 - lr: 1.8196e-05\n",
      "Epoch 16/20\n",
      "61/61 [==============================] - 652s 11s/step - loss: 0.5143 - accuracy: 0.8724 - val_loss: 0.3847 - val_accuracy: 0.8290 - lr: 1.6464e-05\n",
      "Epoch 17/20\n",
      "61/61 [==============================] - 647s 11s/step - loss: 0.4996 - accuracy: 0.8775 - val_loss: 0.4503 - val_accuracy: 0.7907 - lr: 1.4898e-05\n",
      "Epoch 18/20\n",
      "61/61 [==============================] - 642s 11s/step - loss: 0.4857 - accuracy: 0.8863 - val_loss: 0.4536 - val_accuracy: 0.8048 - lr: 1.3480e-05\n",
      "Epoch 19/20\n",
      "61/61 [==============================] - 647s 11s/step - loss: 0.4987 - accuracy: 0.8739 - val_loss: 0.5402 - val_accuracy: 0.7485 - lr: 1.2197e-05\n",
      "Epoch 20/20\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.8744\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.31091532643768e-06.\n",
      "61/61 [==============================] - 647s 11s/step - loss: 0.5003 - accuracy: 0.8744 - val_loss: 0.5379 - val_accuracy: 0.7726 - lr: 3.3109e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2e5858e1b20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Vision Transformer model\n",
    "vit_model = vit.vit_b16(\n",
    "    image_size=img_height,\n",
    "    activation='sigmoid',\n",
    "    pretrained=True,\n",
    "    include_top=True,\n",
    "    pretrained_top=False,\n",
    "    classes=1\n",
    ")\n",
    "\n",
    "# Fine-tune more layers\n",
    "for layer in vit_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with a different optimizer and learning rate\n",
    "vit_model.compile(optimizer=Adam(learning_rate=3e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * math.exp(-0.1)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=8, restore_best_weights=True)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=4, verbose=1, factor=0.3, min_lr=0.000001)\n",
    "callbacks_list = [early, learning_rate_reduction, lr_scheduler]\n",
    "\n",
    "# Compute class weights\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "unique_classes = np.unique(train_generator.classes)\n",
    "weights = compute_sample_weight(class_weight='balanced', y=train_generator.classes)\n",
    "cw = dict(zip(unique_classes, weights))\n",
    "print(cw)\n",
    "\n",
    "# Train the model\n",
    "vit_model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,  # Increase the number of epochs\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=cw,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "vit_model.save('VisionTransformer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 81s 4s/step - loss: 0.3846 - accuracy: 0.8380\n",
      "The testing accuracy is: 83.79705548286438 %\n",
      "20/20 [==============================] - 83s 4s/step\n",
      "Confusion Matrix:\n",
      "[[173  24]\n",
      " [ 75 339]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.70      0.88      0.78       197\n",
      "     Disease       0.93      0.82      0.87       414\n",
      "\n",
      "    accuracy                           0.84       611\n",
      "   macro avg       0.82      0.85      0.83       611\n",
      "weighted avg       0.86      0.84      0.84       611\n",
      "\n",
      "Sensitivity: 81.88%\n",
      "Specificity: 87.82%\n",
      "F1-Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_accu = vit_model.evaluate(test)\n",
    "print('The testing accuracy is:', test_accu[1] * 100, '%')\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = vit_model.predict(test)\n",
    "y_pred = np.round(y_pred).astype(int)  # Chuyển đổi dự đoán thành nhãn nhị phân (0 hoặc 1)\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test.classes\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Compute classification report\n",
    "class_report = classification_report(y_true, y_pred, target_names=['Normal', 'Disease'])\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Extract Sensitivity, Specificity, and F1-Score from confusion matrix\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = sensitivity  # Recall là tên khác của Sensitivity\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f'Sensitivity: {sensitivity * 100:.2f}%')\n",
    "print(f'Specificity: {specificity * 100:.2f}%')\n",
    "print(f'F1-Score: {f1_score:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
