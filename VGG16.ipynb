{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np            \n",
    "import pandas as pd        \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "#Đường dẫn thư mục train và test\n",
    "train_path = r'.\\train'\n",
    "test_path = r'.\\test'\n",
    "val_path = r'.\\val'\n",
    "\n",
    "batch_size = 16 \n",
    "\n",
    "img_height = 500\n",
    "img_width = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1943 images belonging to 2 classes.\n",
      "Found 611 images belonging to 2 classes.\n",
      "Found 497 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = image_gen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "test = test_data_gen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='rgb', \n",
    "    shuffle=False,\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_generator = image_gen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.763157894736842, 1: 1.763157894736842}\n",
      "Epoch 1/25\n",
      "122/122 [==============================] - 1109s 9s/step - loss: 1.8317 - accuracy: 0.6444 - val_loss: 0.6785 - val_accuracy: 0.7103 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "122/122 [==============================] - 864s 7s/step - loss: 1.1248 - accuracy: 0.6830 - val_loss: 0.6272 - val_accuracy: 0.7022 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "122/122 [==============================] - 842s 7s/step - loss: 1.0728 - accuracy: 0.6999 - val_loss: 0.6102 - val_accuracy: 0.7103 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "122/122 [==============================] - 841s 7s/step - loss: 1.0199 - accuracy: 0.7200 - val_loss: 0.6274 - val_accuracy: 0.7223 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "122/122 [==============================] - ETA: 0s - loss: 1.0347 - accuracy: 0.7216\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "122/122 [==============================] - 841s 7s/step - loss: 1.0347 - accuracy: 0.7216 - val_loss: 0.6323 - val_accuracy: 0.7103 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "122/122 [==============================] - 846s 7s/step - loss: 0.9629 - accuracy: 0.7288 - val_loss: 0.5955 - val_accuracy: 0.7203 - lr: 3.0000e-04\n",
      "Epoch 7/25\n",
      "122/122 [==============================] - 845s 7s/step - loss: 0.9557 - accuracy: 0.7401 - val_loss: 0.5525 - val_accuracy: 0.7545 - lr: 3.0000e-04\n",
      "Epoch 8/25\n",
      "122/122 [==============================] - 841s 7s/step - loss: 0.9359 - accuracy: 0.7514 - val_loss: 0.6045 - val_accuracy: 0.7243 - lr: 3.0000e-04\n",
      "Epoch 9/25\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.9396 - accuracy: 0.7447\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "122/122 [==============================] - 840s 7s/step - loss: 0.9396 - accuracy: 0.7447 - val_loss: 0.5532 - val_accuracy: 0.7404 - lr: 3.0000e-04\n",
      "Epoch 10/25\n",
      "122/122 [==============================] - 839s 7s/step - loss: 0.8906 - accuracy: 0.7612 - val_loss: 0.5419 - val_accuracy: 0.7545 - lr: 9.0000e-05\n",
      "Epoch 11/25\n",
      "122/122 [==============================] - 848s 7s/step - loss: 0.8749 - accuracy: 0.7674 - val_loss: 0.5698 - val_accuracy: 0.7264 - lr: 9.0000e-05\n",
      "Epoch 12/25\n",
      "122/122 [==============================] - 839s 7s/step - loss: 0.8554 - accuracy: 0.7658 - val_loss: 0.5385 - val_accuracy: 0.7485 - lr: 9.0000e-05\n",
      "Epoch 13/25\n",
      "122/122 [==============================] - 838s 7s/step - loss: 0.8401 - accuracy: 0.7751 - val_loss: 0.5598 - val_accuracy: 0.7545 - lr: 9.0000e-05\n",
      "Epoch 14/25\n",
      "122/122 [==============================] - ETA: 0s - loss: 0.8261 - accuracy: 0.7777\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "122/122 [==============================] - 838s 7s/step - loss: 0.8261 - accuracy: 0.7777 - val_loss: 0.5567 - val_accuracy: 0.7404 - lr: 9.0000e-05\n",
      "Epoch 15/25\n",
      "122/122 [==============================] - 836s 7s/step - loss: 0.8180 - accuracy: 0.7710 - val_loss: 0.5459 - val_accuracy: 0.7525 - lr: 2.7000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28c013991f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = VGG16(include_top=False, input_shape=(img_height, img_width, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of the pre-trained model\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "cnn = Model(inputs=base_model.input, outputs=predictions)\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.3, min_lr=0.000001)\n",
    "callbacks_list = [early, learning_rate_reduction]\n",
    "\n",
    "# Compute class weights\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "unique_classes = np.unique(train_generator.classes)\n",
    "weights = compute_sample_weight(class_weight='balanced', y=train_generator.classes)\n",
    "cw = dict(zip(unique_classes, weights))\n",
    "print(cw)\n",
    "\n",
    "# Train the model\n",
    "cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=cw,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "cnn.save('vgg16_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 207s 5s/step - loss: 0.5277 - accuracy: 0.7398\n",
      "The testing accuracy is: 73.97708892822266 %\n",
      "39/39 [==============================] - 207s 5s/step\n",
      "Confusion Matrix:\n",
      "[[ 56 141]\n",
      " [ 18 396]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.76      0.28      0.41       197\n",
      "     Disease       0.74      0.96      0.83       414\n",
      "\n",
      "    accuracy                           0.74       611\n",
      "   macro avg       0.75      0.62      0.62       611\n",
      "weighted avg       0.74      0.74      0.70       611\n",
      "\n",
      "Sensitivity: 95.65%\n",
      "Specificity: 28.43%\n",
      "F1-Score: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_accu = cnn.evaluate(test)\n",
    "print('The testing accuracy is:', test_accu[1] * 100, '%')\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = cnn.predict(test)\n",
    "y_pred = np.round(y_pred).astype(int)  # Chuyển đổi dự đoán thành nhãn nhị phân (0 hoặc 1)\n",
    "\n",
    "# Get the true labels\n",
    "y_true = test.classes\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Compute classification report\n",
    "class_report = classification_report(y_true, y_pred, target_names=['Normal', 'Disease'])\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Extract Sensitivity, Specificity, and F1-Score from confusion matrix\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = sensitivity  # Recall là tên khác của Sensitivity\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f'Sensitivity: {sensitivity * 100:.2f}%')\n",
    "print(f'Specificity: {specificity * 100:.2f}%')\n",
    "print(f'F1-Score: {f1_score:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
